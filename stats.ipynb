{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Experiment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def element_frequency(list):\n",
    "    result = {}\n",
    "    for element in list:\n",
    "        if element in result:\n",
    "            result[element] += 1\n",
    "        else:\n",
    "            result[element] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORT_DIR = \"reports\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "column_names = pd.DataFrame(\n",
    "    [\n",
    "        [\"Model\", \"\"], \n",
    "        [\"Version\",\"\"],        \n",
    "        ['Language', \"\"],              \n",
    "        [\"# Attempts\", \"Mean\"], \n",
    "\n",
    "        [\"% Completion\", \"Mean\"], \n",
    "\n",
    "        [\"Wheel\", \"% lost matches\"],\n",
    "        [\"Wheel\", \"% win matches\"],\n",
    "\n",
    "        [\"Wheel\", \"mean vowels buyed\"],\n",
    "        [\"Wheel\", \"Mean duplicated letters\"],\n",
    "        [\"Wheel\", 'Mean final budget'],\n",
    "\n",
    "        ['Guesses','Guesses len mean (right|wrong)'],\n",
    "\n",
    "        ['Strategy', '# first couple diversity'],\n",
    "        ['Strategy', '# first triple diversity'],\n",
    "\n",
    "        [\"Game lost\", \"% insufficent budget error\"],\n",
    "        [\"Game lost\", \"% round limit error\"],\n",
    "        ['Game lost', '% letter not in sentence error'],\n",
    "        ['Game lost', '% vowel not allowed error'],\n",
    "        ['Game lost', '% consonant not allowed error'],\n",
    "        ['Game lost', '% guess error'],\n",
    "        ['Game lost', '% instruction error'],\n",
    "        ['Log','Folder'],\n",
    "    ]\n",
    ")\n",
    "\n",
    "rows = []\n",
    "\n",
    "couple_letter_freq = {}\n",
    "triple_letter_freq = {}\n",
    "\n",
    "for experiment_dir in os.listdir(REPORT_DIR):\n",
    "\n",
    "    stat_file = os.path.join(REPORT_DIR, experiment_dir, \"stats.json\")\n",
    "\n",
    "    if os.path.exists(stat_file):\n",
    "        # Open conf file.\n",
    "        for file in os.listdir(os.path.join(REPORT_DIR, experiment_dir)):\n",
    "            if file.endswith(\".yml\"):\n",
    "                exp_file = file[:-4]\n",
    "                #break\n",
    "                with open(os.path.join(REPORT_DIR, experiment_dir, file)) as stream:\n",
    "                    try:\n",
    "                        yaml_file = yaml.safe_load(stream)\n",
    "                    except yaml.YAMLError as exc:\n",
    "                        print(exc)\n",
    "                break\n",
    "\n",
    "\n",
    "        if 'language' in yaml_file:\n",
    "            lang = yaml_file['language']\n",
    "        else:\n",
    "            lang = \"en\"\n",
    "\n",
    "        # Open stat file.\n",
    "        with open(stat_file, \"r\") as f:\n",
    "            stats = json.load(f)\n",
    "\n",
    "        if 'letter_distribution' in stats:\n",
    "            letter_order = stats['letter_distribution']['letters_order']\n",
    "            letters_freq = stats['letter_distribution']['letters_freq']\n",
    "            df_letter_freq = pd.DataFrame.from_dict(letter_order, orient='index').fillna(0)\n",
    "\n",
    "            first_2, first_3 = [], []\n",
    "            for index, letters in letters_freq.items():\n",
    "                el = letters[0:2]\n",
    "                if len(el) < 2:\n",
    "                    continue\n",
    "                first_2.append(el[0]+el[1])\n",
    "                el = letters[0:3]\n",
    "                if len(el) < 3:\n",
    "                    continue\n",
    "                first_3.append(el[0]+el[1]+el[2])\n",
    "\n",
    "\n",
    "            couple_freq = element_frequency(first_2)\n",
    "            triple_freq = element_frequency(first_3)\n",
    "\n",
    "            couple_diversity = len(couple_freq.keys())\n",
    "            triple_diversity = len(triple_freq.keys())\n",
    "\n",
    "            couple_letter_freq[yaml_file['player']['name']+\" - \"+yaml_file['version']] = couple_freq\n",
    "            triple_letter_freq[yaml_file['player']['name']+\" - \"+yaml_file['version']] = triple_freq\n",
    "        \n",
    "\n",
    "        # try:\n",
    "        letter_not_in_sentence = float(stats['wheel']['% letter not in sentence'])\n",
    "        vowel_not_allowed_error = float(stats['wheel']['% vowel not allowed error'])\n",
    "        consonant_not_allowed_error = float(stats['wheel']['% consonant not allowed error'])\n",
    "        guess_error = float(stats['wheel']['% guess error'])\n",
    "        instruction_error = float(stats['wheel']['% instruction_error'])\n",
    "\n",
    "        rows.append(\n",
    "        [\n",
    "            exp_file,\n",
    "            yaml_file['version'],\n",
    "            lang,\n",
    "            f\"{stats['attempts']['mean']} ± {stats['attempts']['std']}\", \n",
    "            f\"{stats['completion%']['mean']} ± {stats['completion%']['std']}\", \n",
    "            float(stats['wheel']['% lost matches']),\n",
    "            float(stats['wheel']['% win matches']),\n",
    "            f\"{stats['wheel']['mean vowels buyed']} ± {stats['wheel']['std vowels buyed']}\",\n",
    "            f\"{stats['wheel']['mean duplicated letters']} ± {stats['wheel']['std duplicated letters']}\",\n",
    "            f\"{stats['wheel']['mean budget']} ± {stats['wheel']['std budget']}\",\n",
    "            f\"{float(stats['wheel']['right guesses length mean'])} | {float(stats['wheel']['wrong guesses length mean'])}\",\n",
    "            f\"{couple_diversity:.0f}\",\n",
    "            f\"{triple_diversity:.0f}\",\n",
    "            float(stats['wheel']['% insufficent budget']),\n",
    "            float(stats['wheel']['% round limit error']),\n",
    "            letter_not_in_sentence,\n",
    "            vowel_not_allowed_error,\n",
    "            consonant_not_allowed_error,\n",
    "            guess_error,\n",
    "            instruction_error,\n",
    "            experiment_dir,\n",
    "        ]\n",
    "        )\n",
    "    \n",
    "        \n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(25, 6))\n",
    "\n",
    "# Plot couple frequency\n",
    "couple_data = []\n",
    "for key, freq_dict in couple_letter_freq.items():\n",
    "    for couple, freq in freq_dict.items():\n",
    "        couple_data.append((couple, freq, key))\n",
    "\n",
    "df_couple = pd.DataFrame(couple_data, columns=[\"Couple\", \"Frequency\", \"Model\"])\n",
    "couple_order = df_couple.groupby('Couple')['Frequency'].sum().sort_values(ascending=False).index\n",
    "sns.barplot(\n",
    "    x=\"Couple\",\n",
    "    y=\"Frequency\",\n",
    "    hue=\"Model\",\n",
    "    data=df_couple,\n",
    "    ax=axes[0],\n",
    "    order=couple_order\n",
    ")\n",
    "axes[0].set_title('Couple Frequency')\n",
    "axes[0].set_xlabel('Couples')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "# Plot triple frequency\n",
    "triple_data = []\n",
    "for key, freq_dict in triple_letter_freq.items():\n",
    "    for triple, freq in freq_dict.items():\n",
    "        triple_data.append((triple, freq, key))\n",
    "\n",
    "df_triple = pd.DataFrame(triple_data, columns=[\"Triple\", \"Frequency\", \"Model\"])\n",
    "triple_order = df_triple.groupby('Triple')['Frequency'].sum().sort_values(ascending=False).index\n",
    "sns.barplot(\n",
    "    x=\"Triple\",\n",
    "    y=\"Frequency\",\n",
    "    hue=\"Model\",\n",
    "    data=df_triple,\n",
    "    ax=axes[1],\n",
    "    order=triple_order\n",
    ")\n",
    "axes[1].set_title('Triple Frequency')\n",
    "axes[1].set_xlabel('Triples')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "columns = pd.MultiIndex.from_frame(column_names)\n",
    "\n",
    "df = pd.DataFrame(rows, columns=columns)\n",
    "df.sort_values(by=('Wheel','% win matches'), ascending=False, inplace=True, ignore_index=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for only the no-letter-loss version\n",
    "df_nll = df[df[('Version', '')] == 'no-letter-loss']\n",
    "\n",
    "# Extract # Attempts mean and guess error for each model (no-letter-loss only)\n",
    "attempts_mean_nll = df_nll[('# Attempts', 'Mean')].str.split('±').str[0].astype(float)\n",
    "guess_error_nll = df_nll[('Game lost', '% guess error')]\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(attempts_mean_nll, guess_error_nll)\n",
    "\n",
    "# Annotate each point with the model name\n",
    "for i, txt in enumerate(df_nll[('Model', '')]):\n",
    "    plt.annotate(txt, (attempts_mean_nll.iloc[i], guess_error_nll.iloc[i]), fontsize=9, xytext=(5,5), textcoords='offset points')\n",
    "\n",
    "plt.xlabel('# Attempts (Mean)')\n",
    "plt.ylabel('% Guess Error')\n",
    "plt.title('Guess Error vs # Attempts per Model (no-letter-loss only)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMike-",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
